{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script converts files from other formats to edfs.\n",
    "The script takes three arguments:\n",
    " - files: The path to the files to be converted. Can be a file or a folder. If a folder is given then it will search the folder for files that can be converted\n",
    " - output: The path to the output folder.\n",
    " - split: A boolean for whether to split the files into <24 hour, evenly sized chunks. E.g. a 60 hour file gets split into three 20 hour files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import pyedflib\n",
    "import struct\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Convert to EDF.')\n",
    "parser.add_argument('--files', type=str, required=True, help='path to files')\n",
    "parser.add_argument('--output', type=str, required=True,\n",
    "                    help=\"path to output edfs\")\n",
    "parser.add_argument('--split', type=bool, default=False,\n",
    "                    help=\"Whether to split into <24hr segments\")\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All functions take a filepath as input and create a dict with:\n",
    " - sample_rate: The sample rate of the ecg\n",
    " - tracings: An m x n array, where m is the number of channels and n is the length of the ecg\n",
    " - lead_names: A list of strings that has the name of each channel.\n",
    " - dimensions: The dimensions of the ecg. Usually either mV or uV.\n",
    "\n",
    "Most functions have hardcoded values that may need to be changed depending on how the given files are formatted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads .csv files.\n",
    "Assumes that a \"Time (s)\" column is given and uses that to calculate sample rate\n",
    "Assumes that the remaining columns are leads\n",
    "dimensions are given at the end of the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    edf = {\n",
    "        \"sample_rate\": int(1 / (df.loc[1, \"Time (s)\"] - df.loc[0, \"Time (s)\"])),\n",
    "        \"tracings\": df[df.columns[1:]].to_numpy().T,\n",
    "        \"lead_names\": df.columns[1:],\n",
    "        \"dimensions\": [col[-3:-1] if col.endswith((\"(uV)\", \"(mV)\")) else None for col in df.columns[1:]]\n",
    "    }\n",
    "    if None in edf[\"dimensions\"]:\n",
    "        raise ValueError(f\"Unable to recognize dimension in {path}\")\n",
    "\n",
    "    return edf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads .csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_2(path):\n",
    "    df = pd.read_csv(path)\n",
    "    edf = {\n",
    "        \"sample_rate\": 128,\n",
    "        \"tracings\": df[[\"value\"]].to_numpy().T,\n",
    "        \"lead_names\": [\"value\"],\n",
    "        \"dimensions\": [\"mV\"]\n",
    "    }\n",
    "    if None in edf[\"dimensions\"]:\n",
    "        raise ValueError(f\"Unable to recognize dimension in {path}\")\n",
    "\n",
    "    return edf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads .csv files.\n",
    "Dimensions is just '?' because the ppg values were given without units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ppg_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    edf = {\n",
    "        \"sample_rate\": 50,\n",
    "        \"tracings\": np.array(df[\"ppg_green\"])[np.newaxis] / 100,\n",
    "        \"lead_names\": [\"ppg_green\"],\n",
    "        \"dimensions\": [\"?\"]\n",
    "    }\n",
    "\n",
    "    print(edf[\"tracings\"])\n",
    "    print(np.nanmax(edf[\"tracings\"]))\n",
    "    print(np.nanmax(edf[\"tracings\"]))\n",
    "\n",
    "    return edf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads .dat files.\n",
    "path is a path to a folder. Each file in the folder is a .dat file that has the values for a channel.\n",
    "Some values are nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dat(path):\n",
    "    tracings = []\n",
    "    paths = os.listdir(path)\n",
    "    for filename in paths:\n",
    "        with open(os.path.join(path, filename), \"rb\") as file:\n",
    "            buffer = file.read()\n",
    "\n",
    "        tracing = np.array(struct.unpack(\n",
    "            '<'+'h'*(len(buffer)//2), buffer)) / 80.0\n",
    "        tracing[tracing == 0x8000] = np.nan\n",
    "        tracings.append(tracing)\n",
    "\n",
    "    edf = {\n",
    "        \"sample_rate\": 180,\n",
    "        \"tracings\": np.array(tracings),\n",
    "        \"lead_names\": list(map(str, range(len(tracings)))),\n",
    "        \"dimensions\": [\"mV\"] * len(tracings)\n",
    "    }\n",
    "\n",
    "    return edf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads MIT format files.\n",
    "To read an MIT file with wfdb the file extension needs to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mit(path):\n",
    "    if path.endswith(\".dat\"):\n",
    "        path = path[:-4]\n",
    "\n",
    "    tracings, header = wfdb.rdsamp(path)\n",
    "\n",
    "    edf = {\n",
    "        \"sample_rate\": header[\"fs\"],\n",
    "        \"tracings\": tracings.T,\n",
    "        \"lead_names\": header[\"sig_name\"],\n",
    "        \"dimensions\": header[\"units\"]\n",
    "    }\n",
    "\n",
    "    return edf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads .wav files.\n",
    "This is hard coded to ignore the first signal, because the .wav file given had a non-ecg signal.\n",
    "tracings are scaled to be in mV units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wav(path):\n",
    "    tracings, samplerate = sf.read(path, dtype='float32')\n",
    "    tracings = tracings.T[:1]\n",
    "    tracings *= 1e5\n",
    "    edf = {\n",
    "        \"sample_rate\": samplerate,\n",
    "        \"tracings\": tracings,\n",
    "        \"lead_names\": list(map(str, range(len(tracings)))),\n",
    "        \"dimensions\": [\"mV\"] * len(tracings)\n",
    "    }\n",
    "\n",
    "    return edf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads .parquet files.\n",
    "Assumes a \"time\" column is given, and uses it to calculate the sample rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet(path):\n",
    "    df = pd.read_parquet(path)\n",
    "    lead_names = df.columns[1:]\n",
    "    tracings = df[lead_names].to_numpy().T\n",
    "\n",
    "    edf = {\n",
    "        \"sample_rate\": 1e6 / (df.loc[1, \"time\"] - df.loc[0, \"time\"]).microseconds,\n",
    "        \"tracings\": tracings,\n",
    "        \"lead_names\": lead_names,\n",
    "        \"dimensions\": [\"mV\"] * len(tracings)\n",
    "    }\n",
    "\n",
    "    return edf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads .txt files.\n",
    "The given format is values given in each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ascii(path):\n",
    "    f = open(path, \"r\").read()\n",
    "    tracing = list(map(int, f.split(\"\\n\")))\n",
    "    tracings = np.array(tracing)[np.newaxis]\n",
    "\n",
    "    edf = {\n",
    "        \"sample_rate\": 130,\n",
    "        \"tracings\": tracings,\n",
    "        \"lead_names\": [\"1\"],\n",
    "        \"dimensions\": [\"uV\"]\n",
    "    }\n",
    "\n",
    "    return edf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reads .edf files.\n",
    "This doesn't add any new information to the edf.\n",
    "It is only here so if a folder is given as the input path, edf files are also included in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_edf(path):\n",
    "    with pyedflib.EdfReader(path) as edf_file:\n",
    "        signal_headers = edf_file.getSignalHeaders()\n",
    "        num_channels = len(edf_file.getSignalHeaders())\n",
    "        sample_rate = edf_file.getSampleFrequencies()[0]\n",
    "        tracings = []\n",
    "        for i in range(num_channels):\n",
    "            channel = np.array(edf_file.readSignal(i))\n",
    "            tracings.append(channel)\n",
    "\n",
    "    edf = {\n",
    "        \"sample_rate\": sample_rate,\n",
    "        \"tracings\": np.array(tracings),\n",
    "        \"lead_names\": [header[\"label\"] for header in signal_headers],\n",
    "        \"dimensions\": [header[\"dimension\"] for header in signal_headers]\n",
    "    }\n",
    "\n",
    "    return edf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads .txt files.\n",
    "The given format is the same as a csv with spaces separating values.\n",
    "It is assumed three leads are given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(path):\n",
    "    df = pd.read_csv(path, sep=' ', names=[\n",
    "                     'index', 'a', 'b', 'c'], header=None)\n",
    "    edf = {\n",
    "        \"sample_rate\": 500,\n",
    "        \"tracings\": np.array(df[[\"a\", \"b\", \"c\"]]).T,\n",
    "        \"lead_names\": [\"a\", \"b\", \"c\"],\n",
    "        \"dimensions\": [\"uV\", \"uV\", \"uV\"]\n",
    "    }\n",
    "\n",
    "    return edf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads .npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_npy(path):\n",
    "    array = np.load(path)\n",
    "\n",
    "    # Interpolates some missing values.\n",
    "    interp = np.interp(array[:, 0], array[array[:, 2] != -\n",
    "                       2147483648, 0], array[array[:, 2] != -2147483648, 2])\n",
    "    tracings = np.expand_dims(interp, axis=0)\n",
    "\n",
    "    edf = {\n",
    "        \"sample_rate\": 250,\n",
    "        \"tracings\": tracings,\n",
    "        \"lead_names\": [\"\"],\n",
    "        \"dimensions\": [\"uV\"]\n",
    "    }\n",
    "\n",
    "    return edf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writes an edf dict to an edf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_edf(edf, path):\n",
    "    # Fixes the sample rate if it is not an integer\n",
    "    if int(edf[\"sample_rate\"]) != edf[\"sample_rate\"]:\n",
    "        new_value = np.round(edf[\"sample_rate\"] * 12) / 12\n",
    "        if edf[\"sample_rate\"] != new_value:\n",
    "            print(f\"Rounded {edf['sample_rate']} to {new_value}\")\n",
    "            edf[\"sample_rate\"] = new_value\n",
    "\n",
    "    channel_info = {\n",
    "        'sample_rate': edf[\"sample_rate\"],\n",
    "        'physical_max': np.nanmax(edf[\"tracings\"]),\n",
    "        'physical_min': np.nanmin(edf[\"tracings\"])\n",
    "    }\n",
    "\n",
    "    if not path.endswith(\".edf\"):\n",
    "        path = path + \".edf\"\n",
    "\n",
    "    with pyedflib.EdfWriter(path, len(edf[\"tracings\"])) as edf_file:\n",
    "        for i, (lead_name, dimension) in enumerate(zip(edf[\"lead_names\"], edf[\"dimensions\"])):\n",
    "            channel_info['label'] = lead_name\n",
    "            channel_info['dimension'] = dimension\n",
    "            edf_file.setSignalHeader(i, channel_info)\n",
    "\n",
    "        edf_file.writeSamples(edf[\"tracings\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits the output edfs into evenly sized chunks, each less than 24 hours.\n",
    "E.g. 60 hour ecg gets split into three 20 hour ecgs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_edf(edf, path):\n",
    "    n_parts = int(np.ceil(edf[\"tracings\"].shape[1] /\n",
    "                  (edf[\"sample_rate\"] * 86400)))\n",
    "    if n_parts > 1:\n",
    "        tracings = edf[\"tracings\"].copy()\n",
    "        delimitation_indices = np.linspace(\n",
    "            0, tracings.shape[1]-1, n_parts + 1).astype(int)\n",
    "        for part_i, (start_i, end_i) in enumerate(zip(delimitation_indices[:-1], delimitation_indices[1:])):\n",
    "            edf[\"tracings\"] = tracings[:, start_i:end_i]\n",
    "            part_path = path + f\"_part_{part_i+1}\"\n",
    "            write_edf(edf, part_path)\n",
    "\n",
    "    else:\n",
    "        write_edf(edf, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert_file reads a file, determines the file type, and writes the edf(s). If the given file doesn't have a supported file type then it does nothing.\n",
    "convert_folder iterates through a folder and tries to convert files within. It will also search subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_file(filepath, output_filepath):\n",
    "    if filepath.endswith(\".csv\"):\n",
    "        edf = read_csv_2(filepath)\n",
    "\n",
    "    elif filepath.endswith(\".dat\"):\n",
    "        edf = read_mit(filepath)\n",
    "\n",
    "    elif filepath.endswith(\".wav\"):\n",
    "        edf = read_wav(filepath)\n",
    "\n",
    "    elif filepath.endswith(\".parquet\"):\n",
    "        edf = read_parquet(filepath)\n",
    "\n",
    "    elif filepath.endswith(\".edf\"):\n",
    "        edf = read_edf(filepath)\n",
    "\n",
    "    elif filepath.endswith(\".txt\"):\n",
    "        edf = read_txt(filepath)\n",
    "\n",
    "    elif filepath.endswith(\".npy\"):\n",
    "        edf = read_npy(filepath)\n",
    "\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    if args.split:\n",
    "        split_edf(edf, output_filepath)\n",
    "\n",
    "    else:\n",
    "        write_edf(edf, output_filepath)\n",
    "\n",
    "\n",
    "def convert_folder(path, output_path):\n",
    "    file_ends_in_dat = [file.endswith(\".dat\") for file in os.listdir(path)]\n",
    "    if len(file_ends_in_dat) > 0 and all(file_ends_in_dat):\n",
    "        edf = read_dat(path)\n",
    "        if args.split:\n",
    "            split_edf(edf, output_path)\n",
    "\n",
    "        else:\n",
    "            write_edf(edf, output_path)\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    for file in os.listdir(path):\n",
    "        filepath = os.path.join(path, file)\n",
    "        output_filepath = os.path.join(output_path, file)\n",
    "\n",
    "        if os.path.isdir(filepath):\n",
    "            convert_folder(filepath, output_filepath)\n",
    "\n",
    "        else:\n",
    "            convert_file(filepath, output_filepath)\n",
    "\n",
    "\n",
    "def main():\n",
    "    if os.path.isdir(args.files):\n",
    "        convert_folder(args.files, args.output)\n",
    "\n",
    "    else:\n",
    "        convert_file(args.files, args.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
